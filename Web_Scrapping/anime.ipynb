{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# The \"requests\" library makes working with HTTP requests easier\n",
    "# than the built-in urllib libraries.\n",
    "import requests\n",
    "from urllib2 import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<myanimelist.session.Session at 0x10e6e0250>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pip\n",
    "\n",
    "# def install(package):\n",
    "#    pip.main(['install', package])\n",
    "\n",
    "# install('python-mal')\n",
    "\n",
    "# import myanimelist.session\n",
    "# #username=\"teamvulpix\", password=\"2015harvardcs109\"\n",
    "# session = myanimelist.session.Session()\n",
    "# session.login()\n",
    "# bebop = session.anime(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapping the search bar of www.anime-planet.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#48 animes per page with 152 pages = ~7296\n",
    "anime = []\n",
    "for i in xrange(1,153):\n",
    "    anime.append(requests.get('http://www.anime-planet.com/anime/all?sort=title&order=asc&page='+str(i)))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving our anime pages into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save anime into a pickle file.\n",
    "\n",
    "# pickle.dump(anime, open(\"anime_pages.p\", \"wb\"))\n",
    "\n",
    "test1 = open(\"anime_pages.p\",'rb') \n",
    "anime = pickle.load(test1)  \n",
    "test1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding all anime links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = 'http://www.anime-planet.com'\n",
    "\n",
    "all_anime = []\n",
    "for page in anime:\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    animelist = soup.find('ul',attrs={\"class\": \"cardDeck pure-g cd-narrow\"}).find_all(\"li\")\n",
    "    for ani in animelist:\n",
    "        all_anime.append(root + ani.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7281"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_anime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requesting each anime page information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "each_anime = []\n",
    "\n",
    "for i in xrange(len(all_anime)):\n",
    "    each_anime.append(requests.get(all_anime[i]))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving each anime page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save anime into a pickle file.\n",
    "# import pickle\n",
    "\n",
    "#pickle.dump(each_anime, open(\"each_anime.p\", \"wb\"))\n",
    "\n",
    "test2 = open(\"each_anime.p\",'rb') \n",
    "each_anime = pickle.load(test2)  \n",
    "test2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting each anime info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "each_anime_info = {}\n",
    "\n",
    "for anim in each_anime:\n",
    "    anime_info = {}\n",
    "    soup1 = BeautifulSoup(anim.text, \"html.parser\")\n",
    "    name = soup1.find('h1',attrs={\"itemprop\": \"name\"}).contents[0]\n",
    "    altname = soup1.find('h2',attrs={\"class\": \"aka\"})\n",
    "\n",
    "    infos = soup1.find_all('div',attrs={\"class\": \"pure-u-1 pure-u-md-1-5\"})\n",
    "    atype = infos[0]\n",
    "    studio = infos[1].a\n",
    "    date = infos[2].li\n",
    "    date_pub = infos[2].find('span',attrs={'itemprop':'datePublished'})\n",
    "    rating = infos[3].div.span\n",
    "    rank = infos[4]\n",
    "    description = soup1.find('div',attrs={\"itemprop\": \"description\"})\n",
    "    \n",
    "    #get categories\n",
    "    categories_table = soup1.find('div',attrs={\"class\": \"categories\"})\n",
    "    if categories_table is not None:\n",
    "        anime_info['categories'] = [i.a.contents[0] for i in categories_table.ul]\n",
    "    \n",
    "    #get related media\n",
    "    related_table = soup1.find('table',attrs={\"class\": \"pure-table pure-table-striped noHeader\"})\n",
    "    if related_table is not None:\n",
    "        anime_info['related'] = [row.td.a.contents[0] for row in related_table.find_all('tr')]\n",
    "    \n",
    "    anime_info['name'] = name\n",
    "    if altname is not None:\n",
    "        anime_info['altname'] = altname.contents[0]\n",
    "    else:\n",
    "        anime_info['altname'] = ''\n",
    "    if atype is not None:\n",
    "        anime_info['atype'] = atype.contents[0]\n",
    "    else:\n",
    "        anime_info['atype'] = ''\n",
    "    if studio is not None:\n",
    "        anime_info['studio'] = studio.contents[0]\n",
    "    else:\n",
    "        anime_info['studio'] = ''\n",
    "    if date is not None:\n",
    "        anime_info['date'] = date.a.contents[0]\n",
    "    else:\n",
    "        anime_info['date'] = ''\n",
    "    if date_pub is not None:\n",
    "        anime_info['date_pub'] = date_pub.a.contents[0]\n",
    "    else:\n",
    "        anime_info['date'] = ''\n",
    "    if rating is not None:\n",
    "        anime_info['rating'] = rating.contents[0]\n",
    "    else:\n",
    "        anime_info['rating'] = ''\n",
    "    if rank is not None:\n",
    "        anime_info['rank'] = rank.contents[0]\n",
    "    else:\n",
    "        anime_info['rank'] = ''\n",
    "    if description is not None :\n",
    "        if description.p is not None:\n",
    "            anime_info['description'] = description.p.contents[0].string\n",
    "        else:\n",
    "                anime_info['description'] = ''\n",
    "    else:\n",
    "        anime_info['description'] = ''\n",
    "    \n",
    "    if name in each_anime_info.keys():\n",
    "        name+='_2'\n",
    "        \n",
    "    each_anime_info[name] = anime_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  with open('each_anime_info.json', 'w') as fp:\n",
    "#      json.dump(each_anime_info, fp)\n",
    "\n",
    "with open('each_anime_info.json','r') as data_file:    \n",
    "    each_anime_info = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7281"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(each_anime_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
